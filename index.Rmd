---
title: "Homework: Reading in Data"
author: "Firstname Lastname"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(digits = 3)
```


```{r load-sas-libraries, echo = F, message = F, warning = F}

library(SASmarkdown)
sas_enginesetup(sashtml=sashtml)

# sasexe <- "C:/Program Files/SASHome/SASFoundation/9.4/sas.exe"
# sasopts <- "-nosplash -ls 75"

# Linux options (for grading, please leave this in!)
sasexe <- "/usr/local/SASHome/SASFoundation/9.4/bin/sas_en"
sasopts <- "-ls 75"
```

## Instructions
Big picture: Read in the Medicare and Medicaid General Payments Data and conduct an exploratory data analysis. You should use both SAS and R to explore the data, but you might choose to use R for certain tasks and SAS for other tasks. 

When you are finished with the assignment: 

1. Save the file as 04_Lastname_Firstname.Rmd and compile it
2. Commit the Rmd file and corresponding html file to your homework git repo
3. Push the commit to github
4. Locate the Rmd file on github and click on the SHA link for the file
5. Paste the url of the resulting page into Canvas to submit your assignment.

Your assignment must compile on a different computer as long as the saspath is set correctly for that machine. This means you will need to use a local file path when you read the data in via R (and SAS). So when you specify your file path, it should look something like "General_Payment_Data_Sample.csv" with no "/home/xxx/Documents" or "C:\\" in front of it.  

### About the Data

To get this data, I started with the full 2018 dataset, and limited it to cash payments made to medical doctors reported in January. The full dataset is *way* too big - several GB when stored on disk. 

A sample of the full dataset is available in the template repository (and also  [here](https://github.com/srvanderplas/unl-stat850/raw/master/data/General_Payment_Data_Sample.csv)). It's 8MB after extreme trimming of the less useful columns and sampling 25% of the rows. You can read about the data [here](https://openpaymentsdata.cms.gov/about) and [here](https://www.cms.gov/openpayments/). 

### Questions to Address

- Describe the dataset and any interesting things you find within. 
- What tasks are easier in R? SAS?
- What do you find that might need to be cleaned up or corrected before analysis?

You may want to include graphics (using the sample code in the book, or the [R Graph Gallery](https://www.r-graph-gallery.com/)) to show any interesting things you discover. When you include a graph, be sure to provide some contextual description of the information you want someone to take away from the graph.
4
## Data Exploration

### R
(You don't need to keep these headings, but I want you to have a skeleton of what the code chunks should look like)

```{r}
library(readr)
data <- read_csv("https://github.com/srvanderplas/unl-stat850/raw/master/data/General_Payment_Data_Sample.csv")
```

```{r, message = F, warning = F, error = F}
# Load useful packages
library(skimr)   # fancy summary tables
library(tibble)  # fancy data frames
library(dplyr)   # data manipulation
library(ggplot2) # plots

skim(data)
```

From the `skimr` summary table, we can see that none of the variables have missing data (which is really odd), and many of the character variables have only 2-5 unique values. If we investigate, though, we find something interesting:
```{r}
table(data$Recipient_Country)
table(data$Recipient_Province)
table(data$Recipient_Postal_Code)
table(data$Recipient_Country)
```
It appears missing values are indicated with a '.', as in SAS, and not with an NA, as is standard in R. We can fix that with an option to `read_csv`: 

```{r}
data <- read_csv("https://github.com/srvanderplas/unl-stat850/raw/master/data/General_Payment_Data_Sample.csv", na = '.')

skim(data)
```

And now we're getting information that looks a bit more plausible. Not all medical reimbursements are e.g. travel related, or would be expected to have associated charity or drug information. 


The numeric variables in the dataset are primarily ID numbers, but there are two potentially useful pieces of information: Number of payments included, and total reimbursement amount. 

A few other observations from just the table above:
- The smallest payment was for $0.11? That's odd...
- Most payments are for <$500, but there are a few really large reimbursements
- Almost all records are for single payments.

Let's pull out the interesting pieces of each of these observations. I'll use the way you know how to use for now as much as I can (and we'll learn a better way next week with `dplyr`). 

```{r}
# Smallest payment w/ some context?
data[which.min(data$Total_Amount_of_Payment_USDollars),
     c("Nature_of_Payment_or_Transfer_of_Value", "Recipient_State", 
       "Physician_Specialty", "Total_Amount_of_Payment_USDollars")]

# Largest payment w/ some context?
data[which.max(data$Total_Amount_of_Payment_USDollars),
     c("Nature_of_Payment_or_Transfer_of_Value", "Recipient_State", 
       "Physician_Specialty", "Total_Amount_of_Payment_USDollars", "Contextual_Information")]


# define a new skim summary function that counts the number of observations 
# and gets the mean, sd, and histogram
no_ps <- skim_with(numeric = sfl(mean = mean, sd = sd, 
                                 hist = inline_hist, n = length), 
                   append = F)

# large payments w/ some context, for each type of payment?
tmp <- data[data$Total_Amount_of_Payment_USDollars > 500,] %>%
  group_by(Nature_of_Payment_or_Transfer_of_Value) %>%
  no_ps(Total_Amount_of_Payment_USDollars)
# get rid of useless n_missing and complete_rate columns when printing
# yes, this is me being anal-retentive
tmp[,c(1:3, 6:9)]

# I decided to plot this last one out just for fun...
# but that required a little work for the plot to be legible. 
data[data$Number_of_Payments_Included_in_Total_Amount > 1,] %>%
  # Sorry... we're about a week out from knowing this part.
  mutate(Type = strtrim(Nature_of_Payment_or_Transfer_of_Value, 30)) %>%
  # And we're about 4 weeks from seeing this stuff formally
  ggplot(aes(x = Number_of_Payments_Included_in_Total_Amount,
             y = Total_Amount_of_Payment_USDollars)) + 
  geom_point() + 
  facet_wrap(~Type, scales = "free_y")
```

Things that might require some cleaning:
- missing data (already addressed here)
- Categories that may need to be grouped or relabeled
- It may be worth stripping out some of the data (e.g. the 2 payments that are to entities outside of the US)
- There are a lot of different things in this dataset to begin with - anything that groups travel expenses with drug development/reimbursement/etc. is a bit heterogeneous to get useful information out of. 

As the data is assembled by humans, you can just about guarantee some inconsistencies in data entry. Capitalization and punctuation are common offenders - we'll learn how to deal with string and character manipulation in the next couple of weeks. 
```{r}
company_names <- sort(unique(data$Applicable_Manufacturer_or_Applicable_GPO_Making_Payment_Name))
lowercase_companies <- unique(tolower(company_names))



# some capitalization issues that will interfere with aggregation
length(company_names) - length(lowercase_companies)

# some others that are just issues with abbreviations or different company divisions
company_names[116:122]
company_names[396:397]
company_names[399:400]
company_names[409:411]
```

The `qdap` package has a `check_spelling` function which I'm sure would find some interesting issues as well. 

```{r}
table(data$Indicate_Drug_or_Biological_or_Device_or_Medical_Supply_1, useNA = 'ifany')
```

Another thing to check when you're working with data is the distribution of dates/times/etc. To do this we need the `lubridate` package, and we tell it what format our dates are in (month, day, year). It's pretty easy to tell what the days of the week were! More payments get processed on thursdays, it seems, but the Thursday after New Years is popular too - an unusual spike that probably represents a backlog of reimbursements over the holidays.

```{r}
library(lubridate)
# Change character date to date object
data$Date_of_Payment <- mdy(data$Date_of_Payment)
ggplot(data, aes(x = Date_of_Payment)) + stat_bin(geom = "bar")
```

### SAS
Fill in your code in the chunk below.
```{r, engine="sashtml", engine.path=sasexe, engine.opts=sasopts, collectcode = T, error = T}
filename dat "General_Payment_Data_Sample.csv";

PROC IMPORT DATAFILE = dat OUT = openmedpay 
    DBMS = CSV 
    REPLACE; 
    GETNAMES = YES;
    GUESSINGROWS = 22000;
RUN;
    
DATA WORK.openmedpay;
    SET WORK.openmedpay;
    RENAME Applicable_Manufacturer_or_Appli = payer_ID 
           Var13 = payer_Name
           Var14 = payer_State
           Var15 = payer_Country;
RUN;

    
PROC CONTENTS DATA = WORK.openmedpay;
RUN;
```

You can delete the information below if you don't need it, but these are handy tricks for using sasmarkdown. 
```{r tricks, engine="sashtml", engine.path=sasexe, engine.opts=sasopts, error = T}
/* The collectcode=T option lets you reference data in other chunks, just like in R */
  
```
